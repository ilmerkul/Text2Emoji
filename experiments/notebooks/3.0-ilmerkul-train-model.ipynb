{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e417019-b827-47b9-89ca-aa406ef52165",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064e030-020c-4c43-a81c-db904d4dc275",
   "metadata": {},
   "source": [
    "Dependency import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea68b41-0055-4df2-a231-de056d026a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc73719-8980-4029-a457-948e4a85a6e3",
   "metadata": {},
   "source": [
    "Add path of project modules to visible area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6019dccd-8c87-4d47-b676-d566a349d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pynex\\Projects\\github\\Text2Emoji\\notebooks\n"
     ]
    }
   ],
   "source": [
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88e1a383-f1ae-4a57-af7f-d16a4200bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import one_hot\n",
    "from torchinfo import summary\n",
    "from datasets import load_from_disk\n",
    "\n",
    "import sys\n",
    "import signal\n",
    "from datetime import date\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from loguru import logger\n",
    "import tqdm\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from src.model import Text2Emoji\n",
    "from src.parser import Text2EmojiParser\n",
    "from src.dataset import Text2EmojiDataset\n",
    "from src.utils import print_model, seed_all, set_logger\n",
    "from src.utils.train import evaluate_loss_test, print_learn_curve, evaluate_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e05264-7bf8-44e8-80a6-b82f86497717",
   "metadata": {},
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5fd8f28-8e39-460d-9c32-8d564945f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, train_cfg, emoji_vocab_size, pad_idx, path_save):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_epoch = train_cfg.epoch\n",
    "    print_step = train_cfg.print_step\n",
    "    batch_milestones = train_cfg.batch_milestones\n",
    "    batch_sizes = train_cfg.batch_sizes\n",
    "    epoch_emb_requires_grad = train_cfg.epoch_emb_requires_grad\n",
    "    gamma = train_cfg.gamma\n",
    "    lr_0 = train_cfg.lr_0\n",
    "    lr_milestones = train_cfg.lr_milestones\n",
    "\n",
    "    model.to(device=device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr_0)\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=lr_milestones, gamma=gamma)\n",
    "    loss = CrossEntropyLoss()\n",
    "\n",
    "    params = {\n",
    "        \"epochs\": train_config.train_process.epoch,\n",
    "        \"batch_milestones\": batch_milestones,\n",
    "        \"batch_sizes\": batch_sizes,\n",
    "        \"epoch_emb_requires_grad\": epoch_emb_requires_grad,\n",
    "        \"start_learning_rate\": lr_0,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"lr_scheduler\": {\n",
    "            \"type\": \"MultiStepLR\",\n",
    "            \"milestones\": lr_milestones,\n",
    "            \"gamma\": gamma,\n",
    "        },\n",
    "        \"loss_function\": loss.__class__.__name__,\n",
    "        \"metric_function\": 'bleu',\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': []}\n",
    "    batch_step = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    test_learn_curve_increases = 0\n",
    "\n",
    "    train_data_loader, test_data_loader = dataset.get_data_loader(batch_sizes[0], pad_idx)\n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch == epoch_emb_requires_grad:\n",
    "            model.emb_requires_grad()\n",
    "\n",
    "        if epoch in batch_milestones:\n",
    "            train_data_loader, test_data_loader = dataset.get_data_loader(batch_sizes[batch_step], pad_idx)\n",
    "            batch_step += 1\n",
    "        batch_size = batch_sizes[batch_step]\n",
    "\n",
    "        logger.info(f'epoch: {epoch + 1}/{n_epoch}, '\n",
    "                    f'lr: {scheduler.get_last_lr()}, '\n",
    "                    f'batch_size: {batch_size}')\n",
    "        for i, batch in enumerate(tqdm.tqdm(train_data_loader)):\n",
    "            model.train()\n",
    "\n",
    "            batch_en_ids = batch['en_ids']\n",
    "            batch_de_ids = batch['de_ids']\n",
    "            batch_en_ids = batch_en_ids.to(device=device)\n",
    "            batch_de_ids = batch_de_ids.to(device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(batch_en_ids, batch_de_ids)\n",
    "            loss_t = loss(logits, one_hot(batch_de_ids.permute(1, 0)[:, 1:],\n",
    "                                          num_classes=emoji_vocab_size).to(torch.float))\n",
    "            loss_t.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss_t.item()\n",
    "            if i % print_step == 0 and i != 0:\n",
    "                model.eval()\n",
    "\n",
    "                # evaluate\n",
    "                mean_train_loss = train_loss / print_step\n",
    "                train_loss = 0\n",
    "                mean_test_loss = evaluate_loss_test(model, test_data_loader, loss, emoji_vocab_size, device)\n",
    "                mlflow.log_metric('train_loss', mean_train_loss, step=(i // print_step))\n",
    "                mlflow.log_metric('test_loss', mean_test_loss, step=(i // print_step))\n",
    "                logger.info(f'step: {i}/{len(train_data_loader)}, '\n",
    "                            f'train_loss: {mean_train_loss}, '\n",
    "                            f'test_loss: {mean_test_loss}')\n",
    "                history['train_loss'].append(mean_train_loss)\n",
    "                history['test_loss'].append(mean_test_loss)\n",
    "\n",
    "                # save state\n",
    "                checkpoint_path = f'{path_save}/checkpoint_{date.today()}.pth'\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'history': history,\n",
    "                    'model': model.state_dict(),\n",
    "                    'optim': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict(),\n",
    "                    'batch_size': batch_size,\n",
    "                    'loss': loss\n",
    "                }, checkpoint_path)\n",
    "                mlflow.log_artifact(checkpoint_path)\n",
    "                \n",
    "\n",
    "                # callbacks\n",
    "                if len(history['test_loss']) > 1 and history['test_loss'][-2] < history['test_loss'][-1]:\n",
    "                    test_learn_curve_increases += 1\n",
    "                else:\n",
    "                    test_learn_curve_increases = 0\n",
    "\n",
    "                if test_learn_curve_increases > 5:\n",
    "                    return history\n",
    "\n",
    "        # calculate bleu\n",
    "        results = evaluate_bleu(model, dataset, device)\n",
    "        mlflow.log_metric('bleu', results, step=epoch)\n",
    "        logger.info(f'bleu: {results}')\n",
    "\n",
    "        scheduler.step()\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea10cfb4-9ed8-466b-9651-17b9cddff39e",
   "metadata": {},
   "source": [
    "Set logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c82a72-6e22-4aae-8ee9-4937a9ab512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe4edb-fce4-4507-8ccf-250e54b5d060",
   "metadata": {},
   "source": [
    "Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0740f30e-60d5-4db1-9825-0ea9e9b840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load_parser = '../data/parser'\n",
    "path_load_embbeding = '../data/transfer/embbeding'\n",
    "path_load_dataset = '../data/datasets/processed'\n",
    "path_save_checkpoint = '../data/checkpoints'\n",
    "path_save_model = '../models'\n",
    "path_config=\"../configs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde38eb-ce25-496b-8d4f-9a96295f2826",
   "metadata": {},
   "source": [
    "Set configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c11e1f4-03d2-4781-a8b4-d1f9be7a786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(version_base=None, config_path=path_config)\n",
    "cfg = compose(config_name=\"experiment\")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc04d929-24e1-4801-b9d3-431d2e69a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = cfg.processing.special_tokens\n",
    "pad_token, sos_token, eos_token, unk_token = st.pad.token, st.sos.token, st.eos.token, st.unk.token\n",
    "pad_idx, sos_idx, eos_idx, unk_idx = st.pad.id, st.sos.id, st.eos.id, st.unk.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d15921-f374-4e89-b1f9-7af769bf16fe",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425155cd-58e0-47c3-8cb4-4d34cb8d5210",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e144b-832b-41a2-a5bf-cc28a7c66962",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "217a6a63-822a-4d46-b420-5ae2ff3f8451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 17:49:44 | INFO | Dataset load\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Dataset load')\n",
    "dataset = load_from_disk(path_load_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea15003-1f91-463d-9f43-77bacc528b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Text2EmojiDataset(dataset)\n",
    "dataset.train_test_split(cfg.processing.data.train_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "702e2578-e726-4f95-b99e-a96abbbe07d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Text2EmojiParser(pad_token, sos_token, eos_token, unk_token)\n",
    "parser.load(path_load_parser + '/parser.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75791d2-c9a4-4678-b0a7-c46eca53cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embbedings = torch.load(path_load_embbeding + '/embbeding.pt')\n",
    "embbeding_size = embbedings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737c2720-9486-4fe6-8b7c-8547eec89aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-02 17:46:12 | INFO | Model creating\n"
     ]
    }
   ],
   "source": [
    "logger.info('Model creating')\n",
    "model = Text2Emoji(parser.text_vocab_size(), parser.emoji_vocab_size(),\n",
    "                    sos_idx, eos_idx, pad_idx, embbeding_size,\n",
    "                   cfg.model.hidden_size,\n",
    "                   cfg.model.num_layers,\n",
    "                   cfg.model.dropout,\n",
    "                   cfg.model.sup_unsup_ratio)\n",
    "model.init_en_emb(embbedings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "851a91d4-2e7e-40b8-9351-e8f49d655a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Text2Emoji                               --\n",
       "├─Encoder: 1-1                           --\n",
       "│    └─Embedding: 2-1                    (1,152,600)\n",
       "│    └─GRU: 2-2                          3,158,400\n",
       "│    └─Linear: 2-3                       245,350\n",
       "├─Decoder: 1-2                           --\n",
       "│    └─Embedding: 2-4                    133,000\n",
       "│    └─GRUCell: 2-5                      474,600\n",
       "│    └─Linear: 2-6                       466,830\n",
       "├─AttentionLayer: 1-3                    --\n",
       "│    └─Linear: 2-7                       245,350\n",
       "│    └─Tanh: 2-8                         --\n",
       "│    └─Linear: 2-9                       351\n",
       "=================================================================\n",
       "Total params: 5,876,481\n",
       "Trainable params: 4,723,881\n",
       "Non-trainable params: 1,152,600\n",
       "================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cf144-9e4f-452c-8792-f2db8d893d41",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d228bb-d0b1-4bff-b7a1-7835f827a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_capture(sig, frame):\n",
    "    torch.save(model.state_dict(), f'{path_save_model}/SIGINT_model_weights_{date.today()}.pth')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ca77dd-a7bb-41cd-adb4-faedbd5611a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _signal.default_int_handler(signalnum, frame, /)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.signal(signal.SIGINT, signal_capture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ecec7a-3c06-4dae-9094-47c7db51f416",
   "metadata": {},
   "source": [
    "Save on MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74dcfe6d-38b2-490b-a0be-56a9bfab13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "095cdc16-70f3-4a40-90cc-4910c781e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(experiment_config.mlflow_server)\n",
    "mlflow.set_experiment(experiment_config.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87721b21-ece9-48c0-bc38-25b1d0d4d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"1.0-train-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cfc98-2d42-4520-8bd9-4003e6f234aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    model_summary_file = f\"../models/model_{date.today()}.txt\"\n",
    "    with open(model_summary_file, \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(model_summary_file)\n",
    "\n",
    "    logger.info('Model training')\n",
    "    train_history = train_model(model, dataset, cfg.train,\n",
    "                                parser.emoji_vocab_size(), pad_idx,\n",
    "                                path_save_checkpoint)\n",
    "\n",
    "    torch.save(model.state_dict(), f'{path_save_model}/trained_model_weights_{date.today()}.pth')\n",
    "\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
